{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "32f4f7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import CSV\n",
    "using DataFrames\n",
    "# using StatsBase\n",
    "include(\"pred_funcs.jl\")\n",
    "using MLJ\n",
    "# import MLJBase\n",
    "import TableView.showtable\n",
    "using Plots\n",
    "import FileIO\n",
    "import Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d4dbe2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using Distributions.sampler in module Main conflicts with an existing identifier.\n"
     ]
    }
   ],
   "source": [
    "using Turing, Distributions\n",
    "\n",
    "using MCMCChains, StatsPlots\n",
    "\n",
    "using StatsFuns: logistic\n",
    "\n",
    "using Random\n",
    "Random.seed!(0);\n",
    "\n",
    "using StatsBase\n",
    "import MLJBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9a98ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLJLIBSVMInterface.SVC"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MissingImputator = @load MissingImputator pkg=\"BetaML\" verbosity=0\n",
    "XGBoostClassifier = @load XGBoostClassifier verbosity=0  # loads code defining a model type\n",
    "LogisticClassifier = @load LogisticClassifier pkg=\"MLJLinearModels\" verbosity=0;  # loads code defining a model type\n",
    "AdaBoostStumpClassifier = @load AdaBoostStumpClassifier verbosity=0;  # loads code defining a model type\n",
    "EvoTreeClassifier = @load EvoTreeClassifier verbosity=0\n",
    "GradientBoostingClassifier = @load GradientBoostingClassifier verbosity=0\n",
    "EvoTreeGaussian = @load EvoTreeGaussian verbosity=0\n",
    "SVC = @load SVC verbosity=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "21b9e009",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_key, xold, yold = FileIO.load(\"cleaned_data.jld2\",\"sample_key\",\"x\" ,\"y\");\n",
    "xold.col1=collect(1:nrow(xold));\n",
    "filter!(x->!ismissing(x.gt_AF_Mutect),xold);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "2fdc4735",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in 1:ncol(xold), i in 1:nrow(xold)\n",
    "    if !ismissing(xold[i,j]) && (isnan(xold[i,j]) || isinf(xold[i,j]) )\n",
    "        xold[i,j] = missing\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "8abab384",
   "metadata": {},
   "outputs": [],
   "source": [
    "coldrop = []\n",
    "for i in names(xold)\n",
    "    if i == \"col1\"\n",
    "        continue\n",
    "    end\n",
    "    if length(unique(xold[:,i])) < 2 || occursin(\"Pindel\",i) || occursin(\"Lofreq\",i) || occursin(\"Vardict\",i) # || occursin(\"ALT\",i) || occursin(\"REF\",i)\n",
    "        push!(coldrop,i)\n",
    "#         println(i)\n",
    "    end \n",
    "end\n",
    "unique!(coldrop);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "66013b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47003, 83)\n",
      "(47003,)\n",
      "(47003,)\n"
     ]
    }
   ],
   "source": [
    "select!(xold, Not(coldrop));\n",
    "yold = yold[xold.col1]\n",
    "sample_key=sample_key[xold.col1]\n",
    "select!(xold,Not(\"col1\"));\n",
    "println(size(xold))\n",
    "println(size(yold))\n",
    "println(size(sample_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cce493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "4ccef308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>26 rows × 3 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>MPOS_Mutect</th><th>sample_key</th><th>real</th></tr><tr><th></th><th title=\"Union{Missing, Float32}\">Float32?</th><th title=\"String\">String</th><th title=\"Bool\">Bool</th></tr></thead><tbody><tr><th>1</th><td>25.0</td><td>218281_1_100 2:25457243 G&gt;A</td><td>1</td></tr><tr><th>2</th><td>25.0</td><td>218281_1_10 2:25457243 G&gt;A</td><td>1</td></tr><tr><th>3</th><td>25.0</td><td>218281_T 2:25457243 G&gt;A</td><td>1</td></tr><tr><th>4</th><td><em>missing</em></td><td>272341_1_1000 4:106155751 G&gt;A</td><td>1</td></tr><tr><th>5</th><td><em>missing</em></td><td>272341_1_1000 4:106158216 G&gt;A</td><td>1</td></tr><tr><th>6</th><td><em>missing</em></td><td>272341_1_1000 4:106190862 T&gt;C</td><td>1</td></tr><tr><th>7</th><td>28.0</td><td>736399_1_100 4:106190822 C&gt;A</td><td>1</td></tr><tr><th>8</th><td>28.0</td><td>736399_1_100 4:106196829 T&gt;G</td><td>1</td></tr><tr><th>9</th><td>29.0</td><td>736399_1_100 4:106196951 A&gt;G</td><td>1</td></tr><tr><th>10</th><td>28.0</td><td>736399_1_10 4:106190822 C&gt;A</td><td>1</td></tr><tr><th>11</th><td>28.0</td><td>736399_1_10 4:106196829 T&gt;G</td><td>1</td></tr><tr><th>12</th><td>29.0</td><td>736399_1_10 4:106196951 A&gt;G</td><td>1</td></tr><tr><th>13</th><td>28.0</td><td>736399_T 4:106190822 C&gt;A</td><td>1</td></tr><tr><th>14</th><td><em>missing</em></td><td>761809_1_100 2:25457242 C&gt;T</td><td>1</td></tr><tr><th>15</th><td><em>missing</em></td><td>761809_1_100 4:106180783 T&gt;TG</td><td>1</td></tr><tr><th>16</th><td><em>missing</em></td><td>761809_1_100 4:106194000 A&gt;T</td><td>1</td></tr><tr><th>17</th><td>24.0</td><td>761809_1_10 2:25457242 C&gt;T</td><td>1</td></tr><tr><th>18</th><td>24.0</td><td>761809_T 2:25457242 C&gt;T</td><td>1</td></tr><tr><th>19</th><td><em>missing</em></td><td>887041_1_1000 2:198265526 A&gt;G</td><td>1</td></tr><tr><th>20</th><td><em>missing</em></td><td>887041_1_1000 4:106196951 A&gt;G</td><td>1</td></tr><tr><th>21</th><td><em>missing</em></td><td>887041_1_100 2:25505564 G&gt;T</td><td>1</td></tr><tr><th>22</th><td>27.0</td><td>887041_1_100 4:106156163 G&gt;A</td><td>1</td></tr><tr><th>23</th><td>27.0</td><td>887041_1_10 4:106156163 G&gt;A</td><td>1</td></tr><tr><th>24</th><td>29.0</td><td>887041_1_10 4:106196951 A&gt;G</td><td>1</td></tr><tr><th>25</th><td><em>missing</em></td><td>887041_1_5000 2:198265526 A&gt;G</td><td>1</td></tr><tr><th>26</th><td><em>missing</em></td><td>887041_1_5000 4:106196951 A&gt;G</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& MPOS\\_Mutect & sample\\_key & real\\\\\n",
       "\t\\hline\n",
       "\t& Float32? & String & Bool\\\\\n",
       "\t\\hline\n",
       "\t1 & 25.0 & 218281\\_1\\_100 2:25457243 G>A & 1 \\\\\n",
       "\t2 & 25.0 & 218281\\_1\\_10 2:25457243 G>A & 1 \\\\\n",
       "\t3 & 25.0 & 218281\\_T 2:25457243 G>A & 1 \\\\\n",
       "\t4 & \\emph{missing} & 272341\\_1\\_1000 4:106155751 G>A & 1 \\\\\n",
       "\t5 & \\emph{missing} & 272341\\_1\\_1000 4:106158216 G>A & 1 \\\\\n",
       "\t6 & \\emph{missing} & 272341\\_1\\_1000 4:106190862 T>C & 1 \\\\\n",
       "\t7 & 28.0 & 736399\\_1\\_100 4:106190822 C>A & 1 \\\\\n",
       "\t8 & 28.0 & 736399\\_1\\_100 4:106196829 T>G & 1 \\\\\n",
       "\t9 & 29.0 & 736399\\_1\\_100 4:106196951 A>G & 1 \\\\\n",
       "\t10 & 28.0 & 736399\\_1\\_10 4:106190822 C>A & 1 \\\\\n",
       "\t11 & 28.0 & 736399\\_1\\_10 4:106196829 T>G & 1 \\\\\n",
       "\t12 & 29.0 & 736399\\_1\\_10 4:106196951 A>G & 1 \\\\\n",
       "\t13 & 28.0 & 736399\\_T 4:106190822 C>A & 1 \\\\\n",
       "\t14 & \\emph{missing} & 761809\\_1\\_100 2:25457242 C>T & 1 \\\\\n",
       "\t15 & \\emph{missing} & 761809\\_1\\_100 4:106180783 T>TG & 1 \\\\\n",
       "\t16 & \\emph{missing} & 761809\\_1\\_100 4:106194000 A>T & 1 \\\\\n",
       "\t17 & 24.0 & 761809\\_1\\_10 2:25457242 C>T & 1 \\\\\n",
       "\t18 & 24.0 & 761809\\_T 2:25457242 C>T & 1 \\\\\n",
       "\t19 & \\emph{missing} & 887041\\_1\\_1000 2:198265526 A>G & 1 \\\\\n",
       "\t20 & \\emph{missing} & 887041\\_1\\_1000 4:106196951 A>G & 1 \\\\\n",
       "\t21 & \\emph{missing} & 887041\\_1\\_100 2:25505564 G>T & 1 \\\\\n",
       "\t22 & 27.0 & 887041\\_1\\_100 4:106156163 G>A & 1 \\\\\n",
       "\t23 & 27.0 & 887041\\_1\\_10 4:106156163 G>A & 1 \\\\\n",
       "\t24 & 29.0 & 887041\\_1\\_10 4:106196951 A>G & 1 \\\\\n",
       "\t25 & \\emph{missing} & 887041\\_1\\_5000 2:198265526 A>G & 1 \\\\\n",
       "\t26 & \\emph{missing} & 887041\\_1\\_5000 4:106196951 A>G & 1 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m26×3 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m MPOS_Mutect \u001b[0m\u001b[1m sample_key                    \u001b[0m\u001b[1m real \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Float32?    \u001b[0m\u001b[90m String                        \u001b[0m\u001b[90m Bool \u001b[0m\n",
       "─────┼──────────────────────────────────────────────────\n",
       "   1 │        25.0  218281_1_100 2:25457243 G>A    true\n",
       "   2 │        25.0  218281_1_10 2:25457243 G>A     true\n",
       "   3 │        25.0  218281_T 2:25457243 G>A        true\n",
       "   4 │\u001b[90m   missing   \u001b[0m 272341_1_1000 4:106155751 G>A  true\n",
       "   5 │\u001b[90m   missing   \u001b[0m 272341_1_1000 4:106158216 G>A  true\n",
       "   6 │\u001b[90m   missing   \u001b[0m 272341_1_1000 4:106190862 T>C  true\n",
       "   7 │        28.0  736399_1_100 4:106190822 C>A   true\n",
       "   8 │        28.0  736399_1_100 4:106196829 T>G   true\n",
       "   9 │        29.0  736399_1_100 4:106196951 A>G   true\n",
       "  10 │        28.0  736399_1_10 4:106190822 C>A    true\n",
       "  11 │        28.0  736399_1_10 4:106196829 T>G    true\n",
       "  ⋮  │      ⋮                     ⋮                 ⋮\n",
       "  17 │        24.0  761809_1_10 2:25457242 C>T     true\n",
       "  18 │        24.0  761809_T 2:25457242 C>T        true\n",
       "  19 │\u001b[90m   missing   \u001b[0m 887041_1_1000 2:198265526 A>G  true\n",
       "  20 │\u001b[90m   missing   \u001b[0m 887041_1_1000 4:106196951 A>G  true\n",
       "  21 │\u001b[90m   missing   \u001b[0m 887041_1_100 2:25505564 G>T    true\n",
       "  22 │        27.0  887041_1_100 4:106156163 G>A   true\n",
       "  23 │        27.0  887041_1_10 4:106156163 G>A    true\n",
       "  24 │        29.0  887041_1_10 4:106196951 A>G    true\n",
       "  25 │\u001b[90m   missing   \u001b[0m 887041_1_5000 2:198265526 A>G  true\n",
       "  26 │\u001b[90m   missing   \u001b[0m 887041_1_5000 4:106196951 A>G  true\n",
       "\u001b[36m                                          5 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xold.sample_key=sample_key\n",
    "xold.real=[i==true for i in yold]\n",
    "filter(x->x.training>0.5 && x.real && (ismissing(x.MPOS_Mutect) || x.MPOS_Mutect < 30),xold)[:,[\"MPOS_Mutect\",\"sample_key\",\"real\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "0560a685",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "ArgumentError: New columns must have the same length as old columns",
     "output_type": "error",
     "traceback": [
      "ArgumentError: New columns must have the same length as old columns",
      "",
      "Stacktrace:",
      " [1] insert_single_column!(df::DataFrame, v::Vector{String}, col_ind::Symbol)",
      "   @ DataFrames ~/.julia/packages/DataFrames/vuMM8/src/dataframe/dataframe.jl:598",
      " [2] setindex!",
      "   @ ~/.julia/packages/DataFrames/vuMM8/src/dataframe/dataframe.jl:628 [inlined]",
      " [3] setproperty!(df::DataFrame, col_ind::Symbol, v::Vector{String})",
      "   @ DataFrames ~/.julia/packages/DataFrames/vuMM8/src/dataframe/dataframe.jl:634",
      " [4] top-level scope",
      "   @ In[557]:4",
      " [5] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [6] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "# namd=names(xsnv)[13] # 2,6,8,9,13\n",
    "# namd=\"MBQ_Mutect_1\"\n",
    "namd=\"MPOS_Mutect\"\n",
    "xold.sample_key=sample_key\n",
    "xold.real=[i==true for i in yold]\n",
    "print(namd)\n",
    "histogram(collect(skipmissing(filter(x->x.training>0.5 && x.real,xold)[:,namd])),legend=true,label=\"TT\",alpha=0.3,bins=10)\n",
    "histogram!(collect(skipmissing(filter(x->x.training<0.5 && x.real,xold)[:,namd])),label=\"BMT\",alpha=0.3,bins=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "a476f91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xsnv = copy(xold);\n",
    "ysnv = copy(yold);\n",
    "\n",
    "\n",
    "# train2 = findall(x->x,[i>0.5 for i in xsnv.training])\n",
    "# test = findall(x->x,[i<0.5 for i in xsnv.training])\n",
    "\n",
    "\n",
    "train2, test = partition(eachindex(ysnv), 0.7, stratify=ysnv,  shuffle=true, rng=12344);\n",
    "\n",
    "select!(xsnv,Not(\"training\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "ef5b52e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_standardizer!(xsnv,fit_standardizer(xsnv[train2,:]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "bef4c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showtable(xsnv[1:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "8d1ee7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4137"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ismissing.(Matrix(xsnv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "13e58de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{MissingImputator,…} @888\u001b[39m.\n",
      "└ @ MLJBase /Users/alexpanchot/.julia/packages/MLJBase/W4gFl/src/machines.jl:391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12.455284 seconds (68.28 M allocations: 12.513 GiB, 17.42% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{MissingImputator,…} @888\u001b[39m trained 1 time; caches data\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @970\u001b[39m ⏎ `Table{Union{AbstractVector{ScientificTypesBase.Continuous}, AbstractVector{Union{Missing, ScientificTypesBase.Continuous}}}}`\n"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stmach = machine(MissingImputator(K=5),xsnv[train2,:]) \n",
    "@time sttran = fit!(stmach,verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "48d82c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = MLJ.transform(sttran,xsnv);\n",
    "for i in 1:ncol(xsnv)\n",
    "    xsnv[:,i] = tt[i]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "d84dbe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "disallowmissing!(xsnv);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "bd659873",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = copy(train2)\n",
    "x = copy(xsnv);\n",
    "y = copy(ysnv);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "a24aade7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio: 0.0026512265732134693\n",
      "number of new: 16320\n"
     ]
    }
   ],
   "source": [
    "x,y,train = sampler(x,y,train,\"over\",0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "3970cad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = coerce(copy(y),OrderedFactor);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "72860f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49222, 82) 16407\n",
      "(14101, 82) 37\n",
      "(49222,)\n"
     ]
    }
   ],
   "source": [
    "println(size(x[train,:]),\" \",sum([i==true for i in y[train]] ) )\n",
    "println(size(x[test,:]),\" \",sum([i==true for i in y[test]] ) )\n",
    "println(size(y[train]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ed375b",
   "metadata": {},
   "source": [
    "# MLJ Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "94f1177d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7-element Vector{MLJBase.NumericRange{T, MLJBase.Bounded, Symbol} where T}:\n",
       " typename(MLJBase.NumericRange)(Int64, :max_depth, ... )\n",
       " typename(MLJBase.NumericRange)(Float64, :η, ... )\n",
       " typename(MLJBase.NumericRange)(Float64, :γ, ... )\n",
       " typename(MLJBase.NumericRange)(Float64, :λ, ... )\n",
       " typename(MLJBase.NumericRange)(Float64, :α, ... )\n",
       " typename(MLJBase.NumericRange)(Float64, :min_weight, ... )\n",
       " typename(MLJBase.NumericRange)(Int64, :nrounds, ... )"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "r = [\n",
    "    range(EvoTreeClassifier(), :max_depth, lower=1,upper=5),\n",
    "    range(EvoTreeClassifier(), :η, lower=0.0,upper=1.0),\n",
    "    range(EvoTreeClassifier(), :γ, lower=0.0,upper=1.0),\n",
    "    range(EvoTreeClassifier(), :λ, lower=0.0,upper=1.0),\n",
    "    range(EvoTreeClassifier(), :α, lower=0.0,upper=1.0),\n",
    "    range(EvoTreeClassifier(), :min_weight, lower=0.0,upper=1.0),\n",
    "    range(EvoTreeClassifier(), :nrounds, lower=1,upper=10),\n",
    "    \n",
    "    \n",
    "#     range(LogisticClassifier(), :lambda, lower=0.0,upper=1.0),\n",
    "#     range(LogisticClassifier(), :gamma, lower=0.0,upper=1.0),\n",
    "    \n",
    "#     range(SVC(), :degree, lower=1,upper=4),\n",
    "#     range(SVC(), :gamma, lower=0.0,upper=1.0),    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "4b14a840",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{XGBoostClassifier,…} @176\u001b[39m.\n",
      "└ @ MLJBase /Users/alexpanchot/.julia/packages/MLJBase/W4gFl/src/machines.jl:391\n",
      "[1]\ttrain-logloss:0.445040\n",
      "[2]\ttrain-logloss:0.307910\n",
      "[3]\ttrain-logloss:0.221587\n",
      "[4]\ttrain-logloss:0.161240\n",
      "[5]\ttrain-logloss:0.119526\n",
      "[6]\ttrain-logloss:0.089146\n",
      "[7]\ttrain-logloss:0.067344\n",
      "[8]\ttrain-logloss:0.052089\n",
      "[9]\ttrain-logloss:0.040240\n",
      "[10]\ttrain-logloss:0.031409\n",
      "[11]\ttrain-logloss:0.025139\n",
      "[12]\ttrain-logloss:0.019271\n",
      "[13]\ttrain-logloss:0.014970\n",
      "[14]\ttrain-logloss:0.011890\n",
      "[15]\ttrain-logloss:0.009565\n",
      "[16]\ttrain-logloss:0.007547\n",
      "[17]\ttrain-logloss:0.006046\n",
      "[18]\ttrain-logloss:0.005035\n",
      "[19]\ttrain-logloss:0.004328\n",
      "[20]\ttrain-logloss:0.003747\n",
      "[21]\ttrain-logloss:0.003131\n",
      "[22]\ttrain-logloss:0.002681\n",
      "[23]\ttrain-logloss:0.002364\n",
      "[24]\ttrain-logloss:0.001931\n",
      "[25]\ttrain-logloss:0.001707\n",
      "[26]\ttrain-logloss:0.001537\n",
      "[27]\ttrain-logloss:0.001359\n",
      "[28]\ttrain-logloss:0.001235\n",
      "[29]\ttrain-logloss:0.001065\n",
      "[30]\ttrain-logloss:0.000929\n",
      "[31]\ttrain-logloss:0.000822\n",
      "[32]\ttrain-logloss:0.000739\n",
      "[33]\ttrain-logloss:0.000673\n",
      "[34]\ttrain-logloss:0.000615\n",
      "[35]\ttrain-logloss:0.000562\n",
      "[36]\ttrain-logloss:0.000525\n",
      "[37]\ttrain-logloss:0.000488\n",
      "[38]\ttrain-logloss:0.000457\n",
      "[39]\ttrain-logloss:0.000424\n",
      "[40]\ttrain-logloss:0.000400\n",
      "[41]\ttrain-logloss:0.000379\n",
      "[42]\ttrain-logloss:0.000360\n",
      "[43]\ttrain-logloss:0.000346\n",
      "[44]\ttrain-logloss:0.000333\n",
      "[45]\ttrain-logloss:0.000324\n",
      "[46]\ttrain-logloss:0.000312\n",
      "[47]\ttrain-logloss:0.000299\n",
      "[48]\ttrain-logloss:0.000290\n",
      "[49]\ttrain-logloss:0.000281\n",
      "[50]\ttrain-logloss:0.000270\n",
      "[51]\ttrain-logloss:0.000263\n",
      "[52]\ttrain-logloss:0.000258\n",
      "[53]\ttrain-logloss:0.000250\n",
      "[54]\ttrain-logloss:0.000241\n",
      "[55]\ttrain-logloss:0.000237\n",
      "[56]\ttrain-logloss:0.000232\n",
      "[57]\ttrain-logloss:0.000226\n",
      "[58]\ttrain-logloss:0.000221\n",
      "[59]\ttrain-logloss:0.000218\n",
      "[60]\ttrain-logloss:0.000213\n",
      "[61]\ttrain-logloss:0.000209\n",
      "[62]\ttrain-logloss:0.000205\n",
      "[63]\ttrain-logloss:0.000201\n",
      "[64]\ttrain-logloss:0.000198\n",
      "[65]\ttrain-logloss:0.000195\n",
      "[66]\ttrain-logloss:0.000191\n",
      "[67]\ttrain-logloss:0.000188\n",
      "[68]\ttrain-logloss:0.000185\n",
      "[69]\ttrain-logloss:0.000182\n",
      "[70]\ttrain-logloss:0.000178\n",
      "[71]\ttrain-logloss:0.000176\n",
      "[72]\ttrain-logloss:0.000175\n",
      "[73]\ttrain-logloss:0.000172\n",
      "[74]\ttrain-logloss:0.000171\n",
      "[75]\ttrain-logloss:0.000169\n",
      "[76]\ttrain-logloss:0.000167\n",
      "[77]\ttrain-logloss:0.000165\n",
      "[78]\ttrain-logloss:0.000164\n",
      "[79]\ttrain-logloss:0.000163\n",
      "[80]\ttrain-logloss:0.000161\n",
      "[81]\ttrain-logloss:0.000159\n",
      "[82]\ttrain-logloss:0.000157\n",
      "[83]\ttrain-logloss:0.000156\n",
      "[84]\ttrain-logloss:0.000155\n",
      "[85]\ttrain-logloss:0.000154\n",
      "[86]\ttrain-logloss:0.000152\n",
      "[87]\ttrain-logloss:0.000151\n",
      "[88]\ttrain-logloss:0.000150\n",
      "[89]\ttrain-logloss:0.000149\n",
      "[90]\ttrain-logloss:0.000148\n",
      "[91]\ttrain-logloss:0.000146\n",
      "[92]\ttrain-logloss:0.000145\n",
      "[93]\ttrain-logloss:0.000144\n",
      "[94]\ttrain-logloss:0.000142\n",
      "[95]\ttrain-logloss:0.000142\n",
      "[96]\ttrain-logloss:0.000141\n",
      "[97]\ttrain-logloss:0.000140\n",
      "[98]\ttrain-logloss:0.000139\n",
      "[99]\ttrain-logloss:0.000137\n",
      "[100]\ttrain-logloss:0.000136\n",
      "┌ Info: Training \u001b[34mMachine{XGBoostClassifier,…} @176\u001b[39m.\n",
      "└ @ MLJBase /Users/alexpanchot/.julia/packages/MLJBase/W4gFl/src/machines.jl:391\n",
      "[1]\ttrain-logloss:0.445471\n",
      "[2]\ttrain-logloss:0.306429\n",
      "[3]\ttrain-logloss:0.219103\n",
      "[4]\ttrain-logloss:0.158635\n",
      "[5]\ttrain-logloss:0.117360\n",
      "[6]\ttrain-logloss:0.088062\n",
      "[7]\ttrain-logloss:0.066438\n",
      "[8]\ttrain-logloss:0.050490\n",
      "[9]\ttrain-logloss:0.039451\n",
      "[10]\ttrain-logloss:0.031355\n",
      "[11]\ttrain-logloss:0.024126\n",
      "[12]\ttrain-logloss:0.018544\n",
      "[13]\ttrain-logloss:0.014547\n",
      "[14]\ttrain-logloss:0.011285\n",
      "[15]\ttrain-logloss:0.008909\n",
      "[16]\ttrain-logloss:0.007108\n",
      "[17]\ttrain-logloss:0.005620\n",
      "[18]\ttrain-logloss:0.004688\n",
      "[19]\ttrain-logloss:0.003820\n",
      "[20]\ttrain-logloss:0.003260\n",
      "[21]\ttrain-logloss:0.002687\n",
      "[22]\ttrain-logloss:0.002351\n",
      "[23]\ttrain-logloss:0.002072\n",
      "[24]\ttrain-logloss:0.001785\n",
      "[25]\ttrain-logloss:0.001527\n",
      "[26]\ttrain-logloss:0.001404\n",
      "[27]\ttrain-logloss:0.001221\n",
      "[28]\ttrain-logloss:0.001088\n",
      "[29]\ttrain-logloss:0.000983\n",
      "[30]\ttrain-logloss:0.000862\n",
      "[31]\ttrain-logloss:0.000770\n",
      "[32]\ttrain-logloss:0.000704\n",
      "[33]\ttrain-logloss:0.000641\n",
      "[34]\ttrain-logloss:0.000589\n",
      "[35]\ttrain-logloss:0.000542\n",
      "[36]\ttrain-logloss:0.000509\n",
      "[37]\ttrain-logloss:0.000476\n",
      "[38]\ttrain-logloss:0.000443\n",
      "[39]\ttrain-logloss:0.000424\n",
      "[40]\ttrain-logloss:0.000403\n",
      "[41]\ttrain-logloss:0.000382\n",
      "[42]\ttrain-logloss:0.000366\n",
      "[43]\ttrain-logloss:0.000351\n",
      "[44]\ttrain-logloss:0.000335\n",
      "[45]\ttrain-logloss:0.000323\n",
      "[46]\ttrain-logloss:0.000312\n",
      "[47]\ttrain-logloss:0.000302\n",
      "[48]\ttrain-logloss:0.000293\n",
      "[49]\ttrain-logloss:0.000286\n",
      "[50]\ttrain-logloss:0.000278\n",
      "[51]\ttrain-logloss:0.000271\n",
      "[52]\ttrain-logloss:0.000264\n",
      "[53]\ttrain-logloss:0.000257\n",
      "[54]\ttrain-logloss:0.000253\n",
      "[55]\ttrain-logloss:0.000247\n",
      "[56]\ttrain-logloss:0.000241\n",
      "[57]\ttrain-logloss:0.000235\n",
      "[58]\ttrain-logloss:0.000230\n",
      "[59]\ttrain-logloss:0.000226\n",
      "[60]\ttrain-logloss:0.000222\n",
      "[61]\ttrain-logloss:0.000218\n",
      "[62]\ttrain-logloss:0.000215\n",
      "[63]\ttrain-logloss:0.000209\n",
      "[64]\ttrain-logloss:0.000206\n",
      "[65]\ttrain-logloss:0.000203\n",
      "[66]\ttrain-logloss:0.000200\n",
      "[67]\ttrain-logloss:0.000198\n",
      "[68]\ttrain-logloss:0.000194\n",
      "[69]\ttrain-logloss:0.000191\n",
      "[70]\ttrain-logloss:0.000187\n",
      "[71]\ttrain-logloss:0.000185\n",
      "[72]\ttrain-logloss:0.000183\n",
      "[73]\ttrain-logloss:0.000181\n",
      "[74]\ttrain-logloss:0.000178\n",
      "[75]\ttrain-logloss:0.000176\n",
      "[76]\ttrain-logloss:0.000175\n",
      "[77]\ttrain-logloss:0.000173\n",
      "[78]\ttrain-logloss:0.000171\n",
      "[79]\ttrain-logloss:0.000169\n",
      "[80]\ttrain-logloss:0.000167\n",
      "[81]\ttrain-logloss:0.000165\n",
      "[82]\ttrain-logloss:0.000164\n",
      "[83]\ttrain-logloss:0.000161\n",
      "[84]\ttrain-logloss:0.000160\n",
      "[85]\ttrain-logloss:0.000158\n",
      "[86]\ttrain-logloss:0.000158\n",
      "[87]\ttrain-logloss:0.000157\n",
      "[88]\ttrain-logloss:0.000155\n",
      "[89]\ttrain-logloss:0.000154\n",
      "[90]\ttrain-logloss:0.000152\n",
      "[91]\ttrain-logloss:0.000151\n",
      "[92]\ttrain-logloss:0.000150\n",
      "[93]\ttrain-logloss:0.000149\n",
      "[94]\ttrain-logloss:0.000148\n",
      "[95]\ttrain-logloss:0.000148\n",
      "[96]\ttrain-logloss:0.000146\n",
      "[97]\ttrain-logloss:0.000145\n",
      "[98]\ttrain-logloss:0.000144\n",
      "[99]\ttrain-logloss:0.000143\n",
      "[100]\ttrain-logloss:0.000143\n",
      "\u001b[33mEvaluating over 5 folds:  40%[==========>              ]  ETA: 0:00:48\u001b[39m┌ Info: Training \u001b[34mMachine{XGBoostClassifier,…} @176\u001b[39m.\n",
      "└ @ MLJBase /Users/alexpanchot/.julia/packages/MLJBase/W4gFl/src/machines.jl:391\n",
      "[1]\ttrain-logloss:0.445617\n",
      "[2]\ttrain-logloss:0.308832\n",
      "[3]\ttrain-logloss:0.220778\n",
      "[4]\ttrain-logloss:0.160327\n",
      "[5]\ttrain-logloss:0.117723\n",
      "[6]\ttrain-logloss:0.087629\n",
      "[7]\ttrain-logloss:0.066201\n",
      "[8]\ttrain-logloss:0.050650\n",
      "[9]\ttrain-logloss:0.038624\n",
      "[10]\ttrain-logloss:0.030504\n",
      "[11]\ttrain-logloss:0.024124\n",
      "[12]\ttrain-logloss:0.019110\n",
      "[13]\ttrain-logloss:0.015316\n",
      "[14]\ttrain-logloss:0.012151\n",
      "[15]\ttrain-logloss:0.009501\n",
      "[16]\ttrain-logloss:0.007630\n",
      "[17]\ttrain-logloss:0.006305\n",
      "[18]\ttrain-logloss:0.005072\n",
      "[19]\ttrain-logloss:0.004129\n",
      "[20]\ttrain-logloss:0.003541\n",
      "[21]\ttrain-logloss:0.003086\n",
      "[22]\ttrain-logloss:0.002751\n",
      "[23]\ttrain-logloss:0.002496\n",
      "[24]\ttrain-logloss:0.002172\n",
      "[25]\ttrain-logloss:0.001800\n",
      "[26]\ttrain-logloss:0.001555\n",
      "[27]\ttrain-logloss:0.001347\n",
      "[28]\ttrain-logloss:0.001184\n",
      "[29]\ttrain-logloss:0.001019\n",
      "[30]\ttrain-logloss:0.000921\n",
      "[31]\ttrain-logloss:0.000825\n",
      "[32]\ttrain-logloss:0.000744\n",
      "[33]\ttrain-logloss:0.000676\n",
      "[34]\ttrain-logloss:0.000608\n",
      "[35]\ttrain-logloss:0.000569\n",
      "[36]\ttrain-logloss:0.000528\n",
      "[37]\ttrain-logloss:0.000496\n",
      "[38]\ttrain-logloss:0.000467\n",
      "[39]\ttrain-logloss:0.000437\n",
      "[40]\ttrain-logloss:0.000418\n",
      "[41]\ttrain-logloss:0.000398\n",
      "[42]\ttrain-logloss:0.000376\n",
      "[43]\ttrain-logloss:0.000359\n",
      "[44]\ttrain-logloss:0.000342\n",
      "[45]\ttrain-logloss:0.000331\n",
      "[46]\ttrain-logloss:0.000320\n",
      "[47]\ttrain-logloss:0.000306\n",
      "[48]\ttrain-logloss:0.000295\n",
      "[49]\ttrain-logloss:0.000284\n",
      "[50]\ttrain-logloss:0.000276\n",
      "[51]\ttrain-logloss:0.000268\n",
      "[52]\ttrain-logloss:0.000259\n",
      "[53]\ttrain-logloss:0.000253\n",
      "[54]\ttrain-logloss:0.000248\n",
      "[55]\ttrain-logloss:0.000242\n",
      "[56]\ttrain-logloss:0.000237\n",
      "[57]\ttrain-logloss:0.000231\n",
      "[58]\ttrain-logloss:0.000225\n",
      "[59]\ttrain-logloss:0.000221\n",
      "[60]\ttrain-logloss:0.000217\n",
      "[61]\ttrain-logloss:0.000212\n",
      "[62]\ttrain-logloss:0.000208\n",
      "[63]\ttrain-logloss:0.000204\n",
      "[64]\ttrain-logloss:0.000201\n",
      "[65]\ttrain-logloss:0.000196\n",
      "[66]\ttrain-logloss:0.000193\n",
      "[67]\ttrain-logloss:0.000190\n",
      "[68]\ttrain-logloss:0.000189\n",
      "[69]\ttrain-logloss:0.000184\n",
      "[70]\ttrain-logloss:0.000181\n",
      "[71]\ttrain-logloss:0.000178\n",
      "[72]\ttrain-logloss:0.000175\n",
      "[73]\ttrain-logloss:0.000173\n",
      "[74]\ttrain-logloss:0.000171\n",
      "[75]\ttrain-logloss:0.000170\n",
      "[76]\ttrain-logloss:0.000168\n",
      "[77]\ttrain-logloss:0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[78]\ttrain-logloss:0.000165\n",
      "[79]\ttrain-logloss:0.000163\n",
      "[80]\ttrain-logloss:0.000162\n",
      "[81]\ttrain-logloss:0.000159\n",
      "[82]\ttrain-logloss:0.000158\n",
      "[83]\ttrain-logloss:0.000157\n",
      "[84]\ttrain-logloss:0.000156\n",
      "[85]\ttrain-logloss:0.000155\n",
      "[86]\ttrain-logloss:0.000153\n",
      "[87]\ttrain-logloss:0.000152\n",
      "[88]\ttrain-logloss:0.000151\n",
      "[89]\ttrain-logloss:0.000150\n",
      "[90]\ttrain-logloss:0.000149\n",
      "[91]\ttrain-logloss:0.000147\n",
      "[92]\ttrain-logloss:0.000146\n",
      "[93]\ttrain-logloss:0.000145\n",
      "[94]\ttrain-logloss:0.000144\n",
      "[95]\ttrain-logloss:0.000143\n",
      "[96]\ttrain-logloss:0.000142\n",
      "[97]\ttrain-logloss:0.000141\n",
      "[98]\ttrain-logloss:0.000140\n",
      "[99]\ttrain-logloss:0.000140\n",
      "[100]\ttrain-logloss:0.000139\n",
      "\u001b[33mEvaluating over 5 folds:  60%[===============>         ]  ETA: 0:00:32\u001b[39m┌ Info: Training \u001b[34mMachine{XGBoostClassifier,…} @176\u001b[39m.\n",
      "└ @ MLJBase /Users/alexpanchot/.julia/packages/MLJBase/W4gFl/src/machines.jl:391\n",
      "[1]\ttrain-logloss:0.442856\n",
      "[2]\ttrain-logloss:0.304754\n",
      "[3]\ttrain-logloss:0.217836\n",
      "[4]\ttrain-logloss:0.157214\n",
      "[5]\ttrain-logloss:0.115781\n",
      "[6]\ttrain-logloss:0.086592\n",
      "[7]\ttrain-logloss:0.065292\n",
      "[8]\ttrain-logloss:0.049931\n",
      "[9]\ttrain-logloss:0.038510\n",
      "[10]\ttrain-logloss:0.030087\n",
      "[11]\ttrain-logloss:0.023775\n",
      "[12]\ttrain-logloss:0.019365\n",
      "[13]\ttrain-logloss:0.014994\n",
      "[14]\ttrain-logloss:0.011876\n",
      "[15]\ttrain-logloss:0.009391\n",
      "[16]\ttrain-logloss:0.007372\n",
      "[17]\ttrain-logloss:0.005936\n",
      "[18]\ttrain-logloss:0.005043\n",
      "[19]\ttrain-logloss:0.004294\n",
      "[20]\ttrain-logloss:0.003710\n",
      "[21]\ttrain-logloss:0.003274\n",
      "[22]\ttrain-logloss:0.002669\n",
      "[23]\ttrain-logloss:0.002260\n",
      "[24]\ttrain-logloss:0.001919\n",
      "[25]\ttrain-logloss:0.001631\n",
      "[26]\ttrain-logloss:0.001423\n",
      "[27]\ttrain-logloss:0.001242\n",
      "[28]\ttrain-logloss:0.001081\n",
      "[29]\ttrain-logloss:0.000975\n",
      "[30]\ttrain-logloss:0.000867\n",
      "[31]\ttrain-logloss:0.000790\n",
      "[32]\ttrain-logloss:0.000717\n",
      "[33]\ttrain-logloss:0.000659\n",
      "[34]\ttrain-logloss:0.000601\n",
      "[35]\ttrain-logloss:0.000554\n",
      "[36]\ttrain-logloss:0.000518\n",
      "[37]\ttrain-logloss:0.000477\n",
      "[38]\ttrain-logloss:0.000448\n",
      "[39]\ttrain-logloss:0.000422\n",
      "[40]\ttrain-logloss:0.000396\n",
      "[41]\ttrain-logloss:0.000376\n",
      "[42]\ttrain-logloss:0.000361\n",
      "[43]\ttrain-logloss:0.000345\n",
      "[44]\ttrain-logloss:0.000326\n",
      "[45]\ttrain-logloss:0.000314\n",
      "[46]\ttrain-logloss:0.000305\n",
      "[47]\ttrain-logloss:0.000294\n",
      "[48]\ttrain-logloss:0.000287\n",
      "[49]\ttrain-logloss:0.000278\n",
      "[50]\ttrain-logloss:0.000269\n",
      "[51]\ttrain-logloss:0.000262\n",
      "[52]\ttrain-logloss:0.000257\n",
      "[53]\ttrain-logloss:0.000249\n",
      "[54]\ttrain-logloss:0.000241\n",
      "[55]\ttrain-logloss:0.000236\n",
      "[56]\ttrain-logloss:0.000229\n",
      "[57]\ttrain-logloss:0.000225\n",
      "[58]\ttrain-logloss:0.000221\n",
      "[59]\ttrain-logloss:0.000217\n",
      "[60]\ttrain-logloss:0.000214\n",
      "[61]\ttrain-logloss:0.000210\n",
      "[62]\ttrain-logloss:0.000205\n",
      "[63]\ttrain-logloss:0.000201\n",
      "[64]\ttrain-logloss:0.000198\n",
      "[65]\ttrain-logloss:0.000195\n",
      "[66]\ttrain-logloss:0.000192\n",
      "[67]\ttrain-logloss:0.000189\n",
      "[68]\ttrain-logloss:0.000185\n",
      "[69]\ttrain-logloss:0.000183\n",
      "[70]\ttrain-logloss:0.000180\n",
      "[71]\ttrain-logloss:0.000178\n",
      "[72]\ttrain-logloss:0.000175\n",
      "[73]\ttrain-logloss:0.000173\n",
      "[74]\ttrain-logloss:0.000172\n",
      "[75]\ttrain-logloss:0.000169\n",
      "[76]\ttrain-logloss:0.000168\n",
      "[77]\ttrain-logloss:0.000166\n",
      "[78]\ttrain-logloss:0.000164\n",
      "[79]\ttrain-logloss:0.000162\n",
      "[80]\ttrain-logloss:0.000160\n",
      "[81]\ttrain-logloss:0.000159\n",
      "[82]\ttrain-logloss:0.000158\n",
      "[83]\ttrain-logloss:0.000156\n",
      "[84]\ttrain-logloss:0.000155\n",
      "[85]\ttrain-logloss:0.000154\n",
      "[86]\ttrain-logloss:0.000152\n",
      "[87]\ttrain-logloss:0.000151\n",
      "[88]\ttrain-logloss:0.000149\n",
      "[89]\ttrain-logloss:0.000148\n",
      "[90]\ttrain-logloss:0.000148\n",
      "[91]\ttrain-logloss:0.000146\n",
      "[92]\ttrain-logloss:0.000145\n",
      "[93]\ttrain-logloss:0.000144\n",
      "[94]\ttrain-logloss:0.000143\n",
      "[95]\ttrain-logloss:0.000142\n",
      "[96]\ttrain-logloss:0.000141\n",
      "[97]\ttrain-logloss:0.000140\n",
      "[98]\ttrain-logloss:0.000139\n",
      "[99]\ttrain-logloss:0.000138\n",
      "[100]\ttrain-logloss:0.000137\n",
      "\u001b[33mEvaluating over 5 folds:  80%[====================>    ]  ETA: 0:00:15\u001b[39m┌ Info: Training \u001b[34mMachine{XGBoostClassifier,…} @176\u001b[39m.\n",
      "└ @ MLJBase /Users/alexpanchot/.julia/packages/MLJBase/W4gFl/src/machines.jl:391\n",
      "[1]\ttrain-logloss:0.445093\n",
      "[2]\ttrain-logloss:0.307850\n",
      "[3]\ttrain-logloss:0.221393\n",
      "[4]\ttrain-logloss:0.160812\n",
      "[5]\ttrain-logloss:0.117944\n",
      "[6]\ttrain-logloss:0.088766\n",
      "[7]\ttrain-logloss:0.066570\n",
      "[8]\ttrain-logloss:0.051189\n",
      "[9]\ttrain-logloss:0.038669\n",
      "[10]\ttrain-logloss:0.029755\n",
      "[11]\ttrain-logloss:0.023354\n",
      "[12]\ttrain-logloss:0.017965\n",
      "[13]\ttrain-logloss:0.013915\n",
      "[14]\ttrain-logloss:0.010899\n",
      "[15]\ttrain-logloss:0.008493\n",
      "[16]\ttrain-logloss:0.006672\n",
      "[17]\ttrain-logloss:0.005384\n",
      "[18]\ttrain-logloss:0.004478\n",
      "[19]\ttrain-logloss:0.003742\n",
      "[20]\ttrain-logloss:0.003049\n",
      "[21]\ttrain-logloss:0.002550\n",
      "[22]\ttrain-logloss:0.002229\n",
      "[23]\ttrain-logloss:0.001993\n",
      "[24]\ttrain-logloss:0.001692\n",
      "[25]\ttrain-logloss:0.001456\n",
      "[26]\ttrain-logloss:0.001242\n",
      "[27]\ttrain-logloss:0.001124\n",
      "[28]\ttrain-logloss:0.000986\n",
      "[29]\ttrain-logloss:0.000863\n",
      "[30]\ttrain-logloss:0.000765\n",
      "[31]\ttrain-logloss:0.000709\n",
      "[32]\ttrain-logloss:0.000648\n",
      "[33]\ttrain-logloss:0.000597\n",
      "[34]\ttrain-logloss:0.000555\n",
      "[35]\ttrain-logloss:0.000512\n",
      "[36]\ttrain-logloss:0.000475\n",
      "[37]\ttrain-logloss:0.000440\n",
      "[38]\ttrain-logloss:0.000417\n",
      "[39]\ttrain-logloss:0.000395\n",
      "[40]\ttrain-logloss:0.000371\n",
      "[41]\ttrain-logloss:0.000352\n",
      "[42]\ttrain-logloss:0.000340\n",
      "[43]\ttrain-logloss:0.000326\n",
      "[44]\ttrain-logloss:0.000312\n",
      "[45]\ttrain-logloss:0.000301\n",
      "[46]\ttrain-logloss:0.000290\n",
      "[47]\ttrain-logloss:0.000282\n",
      "[48]\ttrain-logloss:0.000276\n",
      "[49]\ttrain-logloss:0.000269\n",
      "[50]\ttrain-logloss:0.000258\n",
      "[51]\ttrain-logloss:0.000252\n",
      "[52]\ttrain-logloss:0.000246\n",
      "[53]\ttrain-logloss:0.000239\n",
      "[54]\ttrain-logloss:0.000232\n",
      "[55]\ttrain-logloss:0.000228\n",
      "[56]\ttrain-logloss:0.000224\n",
      "[57]\ttrain-logloss:0.000219\n",
      "[58]\ttrain-logloss:0.000216\n",
      "[59]\ttrain-logloss:0.000211\n",
      "[60]\ttrain-logloss:0.000205\n",
      "[61]\ttrain-logloss:0.000201\n",
      "[62]\ttrain-logloss:0.000198\n",
      "[63]\ttrain-logloss:0.000194\n",
      "[64]\ttrain-logloss:0.000190\n",
      "[65]\ttrain-logloss:0.000187\n",
      "[66]\ttrain-logloss:0.000183\n",
      "[67]\ttrain-logloss:0.000180\n",
      "[68]\ttrain-logloss:0.000178\n",
      "[69]\ttrain-logloss:0.000175\n",
      "[70]\ttrain-logloss:0.000171\n",
      "[71]\ttrain-logloss:0.000169\n",
      "[72]\ttrain-logloss:0.000167\n",
      "[73]\ttrain-logloss:0.000165\n",
      "[74]\ttrain-logloss:0.000163\n",
      "[75]\ttrain-logloss:0.000161\n",
      "[76]\ttrain-logloss:0.000159\n",
      "[77]\ttrain-logloss:0.000158\n",
      "[78]\ttrain-logloss:0.000156\n",
      "[79]\ttrain-logloss:0.000155\n",
      "[80]\ttrain-logloss:0.000153\n",
      "[81]\ttrain-logloss:0.000151\n",
      "[82]\ttrain-logloss:0.000150\n",
      "[83]\ttrain-logloss:0.000149\n",
      "[84]\ttrain-logloss:0.000147\n",
      "[85]\ttrain-logloss:0.000146\n",
      "[86]\ttrain-logloss:0.000145\n",
      "[87]\ttrain-logloss:0.000143\n",
      "[88]\ttrain-logloss:0.000142\n",
      "[89]\ttrain-logloss:0.000141\n",
      "[90]\ttrain-logloss:0.000140\n",
      "[91]\ttrain-logloss:0.000138\n",
      "[92]\ttrain-logloss:0.000137\n",
      "[93]\ttrain-logloss:0.000137\n",
      "[94]\ttrain-logloss:0.000135\n",
      "[95]\ttrain-logloss:0.000134\n",
      "[96]\ttrain-logloss:0.000133\n",
      "[97]\ttrain-logloss:0.000133\n",
      "[98]\ttrain-logloss:0.000132\n",
      "[99]\ttrain-logloss:0.000131\n",
      "[100]\ttrain-logloss:0.000130\n",
      "\u001b[33mEvaluating over 5 folds: 100%[=========================] Time: 0:01:15\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PerformanceEvaluation object with these fields:\n",
       "  measure, measurement, operation, per_fold,\n",
       "  per_observation, fitted_params_per_fold,\n",
       "  report_per_fold, train_test_pairs\n",
       "Extract:\n",
       "┌─────────────────────────────────────────────┬─────────────┬───────────┬───────\n",
       "│\u001b[22m measure                                     \u001b[0m│\u001b[22m measurement \u001b[0m│\u001b[22m operation \u001b[0m│\u001b[22m per_\u001b[0m ⋯\n",
       "├─────────────────────────────────────────────┼─────────────┼───────────┼───────\n",
       "│ LogLoss(tol = 2.22045e-16)\\e[34m @674\\e[39m │ 0.000692    │ predict   │ Floa ⋯\n",
       "└─────────────────────────────────────────────┴─────────────┴───────────┴───────\n",
       "\u001b[36m                                                                1 column omitted\u001b[0m\n"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_tune = TunedModel(\n",
    "#     model=LogisticClassifier(penalty=:l1),\n",
    "#     model=SVC(),\n",
    "    model=EvoTreeClassifier(),\n",
    "    resampling=StratifiedCV(nfolds=5, rng=123),\n",
    "\n",
    "    tuning=LatinHypercube(),  #     tuning=Grid(resolution=2), \n",
    "    range = r,\n",
    "    n=20,\n",
    "    operation=predict_mode, # use for probabalistic \n",
    "    measure = fnr,  # use for deterministic or with predict_mode for probab \n",
    "#     measure = brier_loss # use for probabalistic \n",
    "    acceleration=CPUThreads(),\n",
    ")\n",
    "\n",
    "machbest = machine(\n",
    "    self_tune,\n",
    "    x[train,:],y[train])\n",
    "# fit!(machbest,verbosity=1 )\n",
    "evaluate!(machbest,verbosity=2,resampling=StratifiedCV(nfolds=5, rng=123) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "66d74a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat=MLJ.predict_mode(machbest, x[test,:]); # probab\n",
    "# yhat=MLJ.predict(machbest, x[test,:]); # determ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "05fc469c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              ┌───────────────────────────┐\n",
       "              │       Ground Truth        │\n",
       "┌─────────────┼─────────────┬─────────────┤\n",
       "│  Predicted  │    false    │    true     │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│    false    │    14056    │     10      │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│    true     │      8      │     27      │\n",
       "└─────────────┴─────────────┴─────────────┘\n"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConfusionMatrix()(yhat,y[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "2eb8c9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82-element Vector{Pair{String, Float64}}:\n",
       "               \"FILTER_Mutect_strand_bias\" => 0.5815291608476004\n",
       "                           \"MFRL_Mutect_2\" => 0.14514253582769632\n",
       " \"total_greater_than_min_alt_count_Mutect\" => 0.0984383130301204\n",
       "                            \"total_Mutect\" => 0.05161511109760357\n",
       "                             \"MPOS_Mutect\" => 0.024147254701723412\n",
       "                              \"ROQ_Mutect\" => 0.022817746816445446\n",
       "                       \"dust_score_Mutect\" => 0.017364040181786555\n",
       "                            \"MBQ_Mutect_2\" => 0.01523401621201679\n",
       "                                 \"alt_len\" => 0.015142995422258762\n",
       "                 \"VARIANT_CLASS_insertion\" => 0.013245623957398877\n",
       "                           \"RefRev_Mutect\" => 0.005660876175123507\n",
       "                            \"MBQ_Mutect_1\" => 0.004939894655197984\n",
       "                        \"gt_AD_alt_Mutect\" => 0.0027025416112541126\n",
       "                                           ⋮\n",
       "                                   \"REF_I\" => 0.0\n",
       "                  \"VARIANT_CLASS_deletion\" => 0.0\n",
       "             \"FILTER_Mutect_weak_evidence\" => 0.0\n",
       "                             \"SYMBOL_NRAS\" => 0.0\n",
       "                     \"dust_score_3_Mutect\" => 0.0\n",
       "                             \"SYMBOL_IDH1\" => 0.0\n",
       "                             \"SYMBOL_NPM1\" => 0.0\n",
       "                            \"SYMBOL_SF3B1\" => 0.0\n",
       "                            \"MMQ_Mutect_2\" => 0.0\n",
       "                                 \"ref_len\" => 0.0\n",
       "                             \"SYMBOL_KRAS\" => 0.0\n",
       "                           \"SYMBOL_DNMT3A\" => 0.0"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report(machbest).best_report.feature_importances # Evo Tree\n",
    "# fitted_params(machbest).best_fitted_params.coefs[sortperm([i[2] for i in fitted_params(machbest).best_fitted_params.coefs])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "5cfb1bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Vector{String}:\n",
       " \"D-953 2:25469600 T>TG\"\n",
       " \"D-1002 X:39921513 C>T\"\n",
       " \"D-1002 X:39922877 G>T\"\n",
       " \"D-1002 X:39932574 G>T\"\n",
       " \"736399_1_100 4:106196829 T>G\"\n",
       " \"D-810 X:39914759 G>A\""
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = DataFrame(x1=yhat,x2=y[test],sample_key=sample_key[test])\n",
    "filter(x-> x.x1==false && x.x2==true ,aa).sample_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "05169626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14101-element MLJBase.UnivariateFiniteVector{Multiclass{2}, Bool, UInt8, Float64}:\n",
       " UnivariateFinite{Multiclass{2}}(false=>0.646, true=>0.354)\n",
       " UnivariateFinite{Multiclass{2}}(false=>0.646, true=>0.354)\n",
       " UnivariateFinite{Multiclass{2}}(false=>0.646, true=>0.354)\n",
       " UnivariateFinite{Multiclass{2}}(false=>0.646, true=>0.354)\n",
       " UnivariateFinite{Multiclass{2}}(false=>0.646, true=>0.354)\n",
       " UnivariateFinite{Multiclass{2}}(false=>0.399, true=>0.601)\n",
       " UnivariateFinite{Multiclass{2}}(false=>0.646, true=>0.354)\n",
       " UnivariateFinite{Multiclass{2}}(false=>0.646, true=>0.354)\n",
       " UnivariateFinite{Multiclass{2}}(false=>0.646, true=>0.354)\n",
       " UnivariateFinite{Multiclass{2}}(false=>0.646, true=>0.354)\n",
       " UnivariateFinite{Multiclass{2}}(false=>0.646, true=>0.354)\n",
       " UnivariateFinite{Multiclass{2}}(false=>0.646, true=>0.354)\n",
       " UnivariateFinite{Multiclass{2}}(false=>0.646, true=>0.354)\n",
       " ⋮\n",
       " UnivariateFinite{Multiclass{2}}(false=>0.646, true=>0.354)\n",
       " UnivariateFinite{Multiclass{2}}(false=>0.612, true=>0.388)\n",
       " UnivariateFinite{Multiclass{2}}(false=>0.646, true=>0.354)\n",
       " UnivariateFinite{Multiclass{2}}(false=>0.646, true=>0.354)\n",
       " UnivariateFinite{Multiclass{2}}(false=>0.646, true=>0.354)\n",
       " UnivariateFinite{Multiclass{2}}(false=>0.646, true=>0.354)\n",
       " UnivariateFinite{Multiclass{2}}(false=>0.646, true=>0.354)\n",
       " UnivariateFinite{Multiclass{2}}(false=>0.646, true=>0.354)\n",
       " UnivariateFinite{Multiclass{2}}(false=>0.646, true=>0.354)\n",
       " UnivariateFinite{Multiclass{2}}(false=>0.646, true=>0.354)\n",
       " UnivariateFinite{Multiclass{2}}(false=>0.646, true=>0.354)\n",
       " UnivariateFinite{Multiclass{2}}(false=>0.646, true=>0.354)"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLJ.predict(machbest, x[test,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06711ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "814c2688ca8a464ca9c1b8ea8ab0c9fb",
   "lastKernelId": "d16b6d12-51eb-44f7-9d5d-9aea82d69bc4"
  },
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
